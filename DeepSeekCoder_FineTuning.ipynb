{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP6BRl+5twQYEvXlPtXSIE/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alen-Scaria1516/DeepSeekCoder-FineTuning/blob/main/DeepSeekCoder_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIjERIWe6H1s",
        "outputId": "994dfca8-be17-4d7b-bc98-325451d1745c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepSeek-Coder'...\n",
            "remote: Enumerating objects: 497, done.\u001b[K\n",
            "remote: Counting objects: 100% (219/219), done.\u001b[K\n",
            "remote: Compressing objects: 100% (119/119), done.\u001b[K\n",
            "remote: Total 497 (delta 160), reused 130 (delta 100), pack-reused 278\u001b[K\n",
            "Receiving objects: 100% (497/497), 12.49 MiB | 23.73 MiB/s, done.\n",
            "Resolving deltas: 100% (219/219), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/deepseek-ai/DeepSeek-Coder.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd DeepSeek-Coder/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-SgOxDK7BW4",
        "outputId": "97a30eb0-c116-4529-d5c7-71e86a2e6074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSeek-Coder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r finetune/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlURZNFu7GQ1",
        "outputId": "f2a49073-2065-4eb1-8dff-2d21bb9cfeed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.1 (from -r finetune/requirements.txt (line 1))\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.14.0 (from -r finetune/requirements.txt (line 2))\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.35.0 (from -r finetune/requirements.txt (line 3))\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.24.1 (from -r finetune/requirements.txt (line 4))\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrdict (from -r finetune/requirements.txt (line 5))\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r finetune/requirements.txt (line 6)) (4.66.4)\n",
            "Collecting deepspeed==0.12.2 (from -r finetune/requirements.txt (line 8))\n",
            "  Downloading deepspeed-0.12.2.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datasets (from -r finetune/requirements.txt (line 9))\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX (from -r finetune/requirements.txt (line 10))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r finetune/requirements.txt (line 1)) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r finetune/requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r finetune/requirements.txt (line 1)) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r finetune/requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r finetune/requirements.txt (line 1)) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->-r finetune/requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->-r finetune/requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->-r finetune/requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->-r finetune/requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->-r finetune/requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->-r finetune/requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->-r finetune/requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->-r finetune/requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->-r finetune/requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->-r finetune/requirements.txt (line 1))\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->-r finetune/requirements.txt (line 1))\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.1->-r finetune/requirements.txt (line 1))\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_hub<0.17,>=0.16.4 (from tokenizers==0.14.0->-r finetune/requirements.txt (line 2))\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0->-r finetune/requirements.txt (line 3)) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0->-r finetune/requirements.txt (line 3)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0->-r finetune/requirements.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0->-r finetune/requirements.txt (line 3)) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0->-r finetune/requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0->-r finetune/requirements.txt (line 3)) (0.4.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.1->-r finetune/requirements.txt (line 4)) (5.9.5)\n",
            "Collecting hjson (from deepspeed==0.12.2->-r finetune/requirements.txt (line 8))\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from deepspeed==0.12.2->-r finetune/requirements.txt (line 8))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.12.2->-r finetune/requirements.txt (line 8)) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.12.2->-r finetune/requirements.txt (line 8)) (2.8.2)\n",
            "Collecting pynvml (from deepspeed==0.12.2->-r finetune/requirements.txt (line 8))\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r finetune/requirements.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r finetune/requirements.txt (line 1)) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->-r finetune/requirements.txt (line 1)) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->-r finetune/requirements.txt (line 1))\n",
            "  Downloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from attrdict->-r finetune/requirements.txt (line 5)) (1.16.0)\n",
            "Collecting pyarrow>=15.0.0 (from datasets->-r finetune/requirements.txt (line 9))\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r finetune/requirements.txt (line 9)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r finetune/requirements.txt (line 9))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r finetune/requirements.txt (line 9)) (2.0.3)\n",
            "Collecting requests (from transformers==4.35.0->-r finetune/requirements.txt (line 3))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->-r finetune/requirements.txt (line 9))\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->-r finetune/requirements.txt (line 9))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r finetune/requirements.txt (line 9)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r finetune/requirements.txt (line 9)) (3.9.5)\n",
            "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting datasets (from -r finetune/requirements.txt (line 9))\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r finetune/requirements.txt (line 9)) (14.0.2)\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.8,>=0.3.0 (from datasets->-r finetune/requirements.txt (line 9))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting datasets (from -r finetune/requirements.txt (line 9))\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r finetune/requirements.txt (line 10)) (3.20.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r finetune/requirements.txt (line 9)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r finetune/requirements.txt (line 9)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r finetune/requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r finetune/requirements.txt (line 9)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r finetune/requirements.txt (line 9)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r finetune/requirements.txt (line 9)) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.0->-r finetune/requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.0->-r finetune/requirements.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.0->-r finetune/requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.0->-r finetune/requirements.txt (line 3)) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->-r finetune/requirements.txt (line 1)) (2.1.5)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets->-r finetune/requirements.txt (line 9))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r finetune/requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r finetune/requirements.txt (line 9)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r finetune/requirements.txt (line 9)) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.12.2->-r finetune/requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.12.2->-r finetune/requirements.txt (line 8)) (2.20.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->-r finetune/requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.12.2-py3-none-any.whl size=1265669 sha256=2ec898170de70a603e7ead0210df77d7a7fd0238220148c2dd3fad3870a5fd74\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/c8/39/10f68166de0a2a12c511c3c0569128b62be534edc9a224782c\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: ninja, lit, hjson, xxhash, tensorboardX, pynvml, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, dill, attrdict, nvidia-cusolver-cu11, nvidia-cudnn-cu11, multiprocess, huggingface_hub, tokenizers, transformers, datasets, triton, torch, deepspeed, accelerate\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.23.4\n",
            "    Uninstalling huggingface-hub-0.23.4:\n",
            "      Successfully uninstalled huggingface-hub-0.23.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.0\n",
            "    Uninstalling triton-2.3.0:\n",
            "      Successfully uninstalled triton-2.3.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.0+cu121\n",
            "    Uninstalling torch-2.3.0+cu121:\n",
            "      Successfully uninstalled torch-2.3.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.24.1 attrdict-2.0.1 datasets-2.14.7 deepspeed-0.12.2 dill-0.3.7 hjson-3.1.0 huggingface_hub-0.16.4 lit-18.1.8 multiprocess-0.70.15 ninja-1.11.1.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pynvml-11.5.3 tensorboardX-2.6.2.2 tokenizers-0.14.0 torch-2.0.1 transformers-4.35.0 triton-2.0.0 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd finetune/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1z7K8-zV8ni",
        "outputId": "c1881c47-5f69-4602-9447-48f5080aa353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSeek-Coder/finetune\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH=\"/content/alpaca_instruct.jsonl\"\n",
        "OUTPUT_PATH=\"/content/DeepSeek-Coder/finetune\"\n",
        "MODEL_PATH=\"deepseek-ai/deepseek-coder-1.3b-instruct\""
      ],
      "metadata": {
        "id": "6dMWbh8R7yEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio -y"
      ],
      "metadata": {
        "id": "NyFdRfdVMWSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e5f4dc-2ce1-4509-c362-fa775f60d4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.0.1\n",
            "Uninstalling torch-2.0.1:\n",
            "  Successfully uninstalled torch-2.0.1\n",
            "Found existing installation: torchvision 0.18.0+cu121\n",
            "Uninstalling torchvision-0.18.0+cu121:\n",
            "  Successfully uninstalled torchvision-0.18.0+cu121\n",
            "Found existing installation: torchaudio 2.3.0+cu121\n",
            "Uninstalling torchaudio-2.3.0+cu121:\n",
            "  Successfully uninstalled torchaudio-2.3.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crP_5O4zYftx",
        "outputId": "55bdc1d7-6896-4275-b51e-c6a2bdef2c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.3.1 (from torch)\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 torch-2.3.1 torchaudio-2.3.1 torchvision-0.18.1 triton-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall deepspeed -y\n",
        "!pip install deepspeed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9D2jUSXZFE0",
        "outputId": "d953ba79-abbf-4a92-e074-cbb2d6cb964f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: deepspeed 0.12.2\n",
            "Uninstalling deepspeed-0.12.2:\n",
            "  Successfully uninstalled deepspeed-0.12.2\n",
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.14.4.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed) (3.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.11.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.25.2)\n",
            "Collecting nvidia-ml-py (from deepspeed)\n",
            "  Downloading nvidia_ml_py-12.555.43-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.8.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.66.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.14.4-py3-none-any.whl size=1445515 sha256=d8b53dad33aedb8ed31c42970f116b1bba058c537d57d0b0529a3b48d9df83ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/bc/a3/608e90bbb301848b78fd75d24d6d43ba3074de968fc0e397ac\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: nvidia-ml-py, deepspeed\n",
            "Successfully installed deepspeed-0.14.4 nvidia-ml-py-12.555.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KBBeg1GZQ0K",
        "outputId": "73a4152f-83d8-4aba-bb5d-760ed20160c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.1+cu121\n",
            "12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!deepspeed finetune_deepseekcoder.py \\\n",
        "    --model_name_or_path $MODEL_PATH \\\n",
        "    --data_path $DATA_PATH \\\n",
        "    --output_dir $OUTPUT_PATH \\\n",
        "    --num_train_epochs 3 \\\n",
        "    --model_max_length 1024 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 1 \\\n",
        "    --gradient_accumulation_steps 4 \\\n",
        "    --evaluation_strategy \"no\" \\\n",
        "    --save_strategy \"steps\" \\\n",
        "    --save_steps 100 \\\n",
        "    --save_total_limit 100 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --warmup_steps 10 \\\n",
        "    --logging_steps 1 \\\n",
        "    --lr_scheduler_type \"cosine\" \\\n",
        "    --gradient_checkpointing True \\\n",
        "    --report_to \"tensorboard\" \\\n",
        "    --deepspeed configs/ds_config_zero3.json \\\n",
        "    --fp16 True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7AjnSv78zBO",
        "outputId": "7bb55591-d52f-49a4-995b-86c318c97481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-07-16 16:36:34,484] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "[2024-07-16 16:36:37,573] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2024-07-16 16:36:37,574] [INFO] [runner.py:568:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None finetune_deepseekcoder.py --model_name_or_path deepseek-ai/deepseek-coder-1.3b-instruct --data_path /content/alpaca_instruct.jsonl --output_dir /content/DeepSeek-Coder/finetune --num_train_epochs 3 --model_max_length 1024 --per_device_train_batch_size 16 --per_device_eval_batch_size 1 --gradient_accumulation_steps 4 --evaluation_strategy no --save_strategy steps --save_steps 100 --save_total_limit 100 --learning_rate 2e-5 --warmup_steps 10 --logging_steps 1 --lr_scheduler_type cosine --gradient_checkpointing True --report_to tensorboard --deepspeed configs/ds_config_zero3.json --fp16 True\n",
            "[2024-07-16 16:36:39,405] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "[2024-07-16 16:36:43,025] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.2\n",
            "[2024-07-16 16:36:43,025] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-07-16 16:36:43,025] [INFO] [launch.py:139:main] 0 NCCL_VERSION=2.19.3-1\n",
            "[2024-07-16 16:36:43,025] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2024-07-16 16:36:43,025] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.2\n",
            "[2024-07-16 16:36:43,025] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2024-07-16 16:36:43,025] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-07-16 16:36:43,025] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2024-07-16 16:36:43,025] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2024-07-16 16:36:43,025] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2024-07-16 16:36:43,025] [INFO] [launch.py:164:main] dist_world_size=1\n",
            "[2024-07-16 16:36:43,025] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2024-07-16 16:36:43,026] [INFO] [launch.py:256:main] process 8359 spawned with command: ['/usr/bin/python3', '-u', 'finetune_deepseekcoder.py', '--local_rank=0', '--model_name_or_path', 'deepseek-ai/deepseek-coder-1.3b-instruct', '--data_path', '/content/alpaca_instruct.jsonl', '--output_dir', '/content/DeepSeek-Coder/finetune', '--num_train_epochs', '3', '--model_max_length', '1024', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '100', '--save_total_limit', '100', '--learning_rate', '2e-5', '--warmup_steps', '10', '--logging_steps', '1', '--lr_scheduler_type', 'cosine', '--gradient_checkpointing', 'True', '--report_to', 'tensorboard', '--deepspeed', 'configs/ds_config_zero3.json', '--fp16', 'True']\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "2024-07-16 16:36:48.246853: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-16 16:36:48.246901: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-16 16:36:48.342805: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-16 16:36:50.471731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "[2024-07-16 16:36:53,131] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n",
            "[2024-07-16 16:36:54,697] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-07-16 16:36:54,697] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "====================================================================================================\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "cache_dir=None,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=configs/ds_config_zero3.json,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/DeepSeek-Coder/finetune/runs/Jul16_16-36-53_866e1da0d927,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=1.0,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=cosine,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "model_max_length=1024,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=/content/DeepSeek-Coder/finetune,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=1,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/DeepSeek-Coder/finetune,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=100,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=10,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "PAD Token: <｜end▁of▁sentence｜> 32014\n",
            "BOS Token <｜begin▁of▁sentence｜> 32013\n",
            "EOS Token <|EOT|> 32021\n",
            "Load tokenizer from deepseek-ai/deepseek-coder-1.3b-instruct over.\n",
            "[2024-07-16 16:37:02,505] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 219, num_elems = 1.35B\n",
            "Load model from deepseek-ai/deepseek-coder-1.3b-instruct over.\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n",
            "Training dataset samples: 108\n",
            "Sample 11 of the training set: [32013, 2042, 417, 274, 20926, 14244, 20391, 11, 26696, 254, 20676, 8041, 74, 339, 8589, 2008, 11, 6908, 457, 20676, 8041, 74, 7958, 11, 285, 340, 885, 3495, 4301, 4512, 276, 4531, 8214, 13, 1487, 4636, 2223, 13143, 4301, 11, 5411, 285, 13936, 4447, 11, 285, 746, 2159, 12, 13517, 250, 8214, 4301, 11, 340, 540, 20857, 276, 3495, 13, 185, 13518, 3649, 3475, 25, 185, 2042, 417, 274, 6973, 17308, 7718, 774, 482, 3059, 285, 2594, 4287, 3853, 408, 17308, 6, 82, 279, 12031, 18866, 1242, 467, 307, 12591, 14, 3963, 13, 185, 24310, 491, 482, 330, 5728, 372, 5340, 449, 793, 245, 3794, 491, 409, 245, 5785, 344, 4704, 833, 245, 3794, 491, 13, 9338, 387, 245, 6369, 1027, 13147, 491, 13, 7909, 6511, 13775, 2974, 13, 12833, 5787, 2090, 31354, 185, 13518, 21289, 25, 185, 10252, 9611, 207, 185, 185, 1659, 507, 13147, 491, 611, 473, 440, 31, 14, 18870, 14, 3963, 14, 13095, 491, 1, 185, 207, 185, 11651, 1155, 13147, 491, 5052, 1027, 822, 507, 185, 207, 967, 1013, 24310, 491, 18934, 28, 1, 406, 1027, 1, 29, 5052, 1027, 27, 14, 24310, 491, 29, 185, 92, 10252, 185, 32021], [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 10252, 9611, 207, 185, 185, 1659, 507, 13147, 491, 611, 473, 440, 31, 14, 18870, 14, 3963, 14, 13095, 491, 1, 185, 207, 185, 11651, 1155, 13147, 491, 5052, 1027, 822, 507, 185, 207, 967, 1013, 24310, 491, 18934, 28, 1, 406, 1027, 1, 29, 5052, 1027, 27, 14, 24310, 491, 29, 185, 92, 10252, 185, 32021].\n",
            "Sample 11 of the training set: <｜begin▁of▁sentence｜>You are an AI programming assistant, utilizing the DeepSeek Coder model, developed by DeepSeek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\n",
            "### Instruction:\n",
            "You are an amazing UI expert who can learn and create complex frontend UI's in NextJS using shadcn/ui.\n",
            "Badge can be described as Displays a badge or a component that looks like a badge. Generate a Outline Badge. Return ONLY code. DO NOT give explanations\n",
            "### Response:\n",
            "```javascript \n",
            "\n",
            " import { Badge } from \"@/components/ui/badge\"\n",
            " \n",
            "export function BadgeOutline() {\n",
            "  return <Badge variant=\"outline\">Outline</Badge>\n",
            "}```\n",
            "<|EOT|>.\n",
            "Sample 54 of the training set: [32013, 2042, 417, 274, 20926, 14244, 20391, 11, 26696, 254, 20676, 8041, 74, 339, 8589, 2008, 11, 6908, 457, 20676, 8041, 74, 7958, 11, 285, 340, 885, 3495, 4301, 4512, 276, 4531, 8214, 13, 1487, 4636, 2223, 13143, 4301, 11, 5411, 285, 13936, 4447, 11, 285, 746, 2159, 12, 13517, 250, 8214, 4301, 11, 340, 540, 20857, 276, 3495, 13, 185, 13518, 3649, 3475, 25, 185, 2042, 417, 274, 6973, 17308, 7718, 774, 482, 3059, 285, 2594, 4287, 3853, 408, 17308, 6, 82, 279, 12031, 18866, 1242, 467, 307, 12591, 14, 3963, 13, 185, 6546, 506, 7118, 482, 330, 5728, 372, 11650, 1049, 629, 12, 2915, 6523, 5785, 365, 4475, 17654, 14898, 13, 9338, 387, 245, 17645, 506, 7118, 13, 7909, 6511, 13775, 2974, 13, 12833, 5787, 2090, 31354, 185, 13518, 21289, 25, 185, 10252, 9611, 207, 185, 185, 1659, 507, 185, 207, 17645, 2778, 47, 11, 185, 207, 17645, 2778, 47, 6725, 11, 185, 207, 17645, 2778, 4538, 654, 268, 1268, 11, 185, 207, 17645, 2778, 4538, 13947, 11, 185, 92, 473, 440, 31, 14, 18870, 14, 3963, 14, 3584, 12, 301, 79, 1, 185, 207, 185, 11651, 1155, 17645, 2778, 47, 10784, 78, 822, 507, 185, 207, 967, 334, 185, 874, 6546, 2778, 47, 3034, 9409, 28, 90, 21, 92, 29, 185, 2116, 6546, 2778, 47, 6725, 29, 185, 1102, 6546, 2778, 4538, 13947, 3750, 28, 90, 15, 92, 889, 29, 185, 1102, 6546, 2778, 4538, 13947, 3750, 28, 90, 16, 92, 889, 29, 185, 1102, 6546, 2778, 4538, 13947, 3750, 28, 90, 17, 92, 889, 29, 185, 2116, 14, 6546, 2778, 47, 6725, 29, 185, 2116, 6546, 2778, 4538, 654, 268, 1268, 889, 29, 185, 2116, 6546, 2778, 47, 6725, 29, 185, 1102, 6546, 2778, 4538, 13947, 3750, 28, 90, 18, 92, 889, 29, 185, 1102, 6546, 2778, 4538, 13947, 3750, 28, 90, 19, 92, 889, 29, 185, 1102, 6546, 2778, 4538, 13947, 3750, 28, 90, 20, 92, 889, 29, 185, 2116, 14, 6546, 2778, 47, 6725, 29, 185, 874, 14, 6546, 2778, 47, 29, 185, 207, 2189, 185, 92, 10252, 185, 32021], [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 10252, 9611, 207, 185, 185, 1659, 507, 185, 207, 17645, 2778, 47, 11, 185, 207, 17645, 2778, 47, 6725, 11, 185, 207, 17645, 2778, 4538, 654, 268, 1268, 11, 185, 207, 17645, 2778, 4538, 13947, 11, 185, 92, 473, 440, 31, 14, 18870, 14, 3963, 14, 3584, 12, 301, 79, 1, 185, 207, 185, 11651, 1155, 17645, 2778, 47, 10784, 78, 822, 507, 185, 207, 967, 334, 185, 874, 6546, 2778, 47, 3034, 9409, 28, 90, 21, 92, 29, 185, 2116, 6546, 2778, 47, 6725, 29, 185, 1102, 6546, 2778, 4538, 13947, 3750, 28, 90, 15, 92, 889, 29, 185, 1102, 6546, 2778, 4538, 13947, 3750, 28, 90, 16, 92, 889, 29, 185, 1102, 6546, 2778, 4538, 13947, 3750, 28, 90, 17, 92, 889, 29, 185, 2116, 14, 6546, 2778, 47, 6725, 29, 185, 2116, 6546, 2778, 4538, 654, 268, 1268, 889, 29, 185, 2116, 6546, 2778, 47, 6725, 29, 185, 1102, 6546, 2778, 4538, 13947, 3750, 28, 90, 18, 92, 889, 29, 185, 1102, 6546, 2778, 4538, 13947, 3750, 28, 90, 19, 92, 889, 29, 185, 1102, 6546, 2778, 4538, 13947, 3750, 28, 90, 20, 92, 889, 29, 185, 2116, 14, 6546, 2778, 47, 6725, 29, 185, 874, 14, 6546, 2778, 47, 29, 185, 207, 2189, 185, 92, 10252, 185, 32021].\n",
            "Sample 54 of the training set: <｜begin▁of▁sentence｜>You are an AI programming assistant, utilizing the DeepSeek Coder model, developed by DeepSeek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\n",
            "### Instruction:\n",
            "You are an amazing UI expert who can learn and create complex frontend UI's in NextJS using shadcn/ui.\n",
            "Input OTP can be described as Accessible one-time password component with copy paste functionality. Generate a Input OTP. Return ONLY code. DO NOT give explanations\n",
            "### Response:\n",
            "```javascript \n",
            "\n",
            " import {\n",
            "  InputOTP,\n",
            "  InputOTPGroup,\n",
            "  InputOTPSeparator,\n",
            "  InputOTPSlot,\n",
            "} from \"@/components/ui/input-otp\"\n",
            " \n",
            "export function InputOTPDemo() {\n",
            "  return (\n",
            "    <InputOTP maxLength={6}>\n",
            "      <InputOTPGroup>\n",
            "        <InputOTPSlot index={0} />\n",
            "        <InputOTPSlot index={1} />\n",
            "        <InputOTPSlot index={2} />\n",
            "      </InputOTPGroup>\n",
            "      <InputOTPSeparator />\n",
            "      <InputOTPGroup>\n",
            "        <InputOTPSlot index={3} />\n",
            "        <InputOTPSlot index={4} />\n",
            "        <InputOTPSlot index={5} />\n",
            "      </InputOTPGroup>\n",
            "    </InputOTP>\n",
            "  )\n",
            "}```\n",
            "<|EOT|>.\n",
            "Sample 28 of the training set: [32013, 2042, 417, 274, 20926, 14244, 20391, 11, 26696, 254, 20676, 8041, 74, 339, 8589, 2008, 11, 6908, 457, 20676, 8041, 74, 7958, 11, 285, 340, 885, 3495, 4301, 4512, 276, 4531, 8214, 13, 1487, 4636, 2223, 13143, 4301, 11, 5411, 285, 13936, 4447, 11, 285, 746, 2159, 12, 13517, 250, 8214, 4301, 11, 340, 540, 20857, 276, 3495, 13, 185, 13518, 3649, 3475, 25, 185, 2042, 417, 274, 6973, 17308, 7718, 774, 482, 3059, 285, 2594, 4287, 3853, 408, 17308, 6, 82, 279, 12031, 18866, 1242, 467, 307, 12591, 14, 3963, 13, 185, 7115, 2273, 482, 330, 5728, 372, 338, 2675, 344, 5170, 254, 2664, 276, 28048, 1433, 10654, 285, 441, 10654, 13, 9338, 387, 245, 7365, 2273, 13, 7909, 6511, 13775, 2974, 13, 12833, 5787, 2090, 31354, 185, 13518, 21289, 25, 185, 10252, 9611, 207, 185, 185, 440, 2346, 4651, 1, 185, 207, 185, 1892, 507, 7365, 2273, 611, 473, 440, 31, 14, 18870, 14, 3963, 14, 18898, 1, 185, 207, 185, 11651, 1155, 7365, 2273, 10784, 78, 822, 507, 185, 207, 967, 334, 185, 874, 1108, 23727, 28, 1, 19327, 5012, 12, 4679, 2507, 12, 87, 12, 17, 1, 29, 185, 2116, 7115, 2273, 1975, 28, 1, 31328, 1, 889, 29, 185, 2116, 1206, 185, 436, 11775, 1978, 28, 1, 31328, 1, 185, 436, 23727, 28, 1, 818, 12, 3069, 5742, 12, 26813, 5877, 12, 11373, 20098, 12, 12687, 25, 21769, 12, 1263, 12, 20896, 20098, 12, 12687, 25, 424, 8768, 12, 22, 15, 1, 185, 1032, 29, 185, 436, 6121, 1597, 3757, 285, 4469, 185, 2116, 14, 1206, 29, 185, 874, 14, 1108, 29, 185, 207, 2189, 185, 92, 10252, 185, 32021], [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 10252, 9611, 207, 185, 185, 440, 2346, 4651, 1, 185, 207, 185, 1892, 507, 7365, 2273, 611, 473, 440, 31, 14, 18870, 14, 3963, 14, 18898, 1, 185, 207, 185, 11651, 1155, 7365, 2273, 10784, 78, 822, 507, 185, 207, 967, 334, 185, 874, 1108, 23727, 28, 1, 19327, 5012, 12, 4679, 2507, 12, 87, 12, 17, 1, 29, 185, 2116, 7115, 2273, 1975, 28, 1, 31328, 1, 889, 29, 185, 2116, 1206, 185, 436, 11775, 1978, 28, 1, 31328, 1, 185, 436, 23727, 28, 1, 818, 12, 3069, 5742, 12, 26813, 5877, 12, 11373, 20098, 12, 12687, 25, 21769, 12, 1263, 12, 20896, 20098, 12, 12687, 25, 424, 8768, 12, 22, 15, 1, 185, 1032, 29, 185, 436, 6121, 1597, 3757, 285, 4469, 185, 2116, 14, 1206, 29, 185, 874, 14, 1108, 29, 185, 207, 2189, 185, 92, 10252, 185, 32021].\n",
            "Sample 28 of the training set: <｜begin▁of▁sentence｜>You are an AI programming assistant, utilizing the DeepSeek Coder model, developed by DeepSeek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\n",
            "### Instruction:\n",
            "You are an amazing UI expert who can learn and create complex frontend UI's in NextJS using shadcn/ui.\n",
            "Checkbox can be described as A control that allows the user to toggle between checked and not checked. Generate a Checkbox. Return ONLY code. DO NOT give explanations\n",
            "### Response:\n",
            "```javascript \n",
            "\n",
            " \"use client\"\n",
            " \n",
            "import { Checkbox } from \"@/components/ui/checkbox\"\n",
            " \n",
            "export function CheckboxDemo() {\n",
            "  return (\n",
            "    <div className=\"flex items-center space-x-2\">\n",
            "      <Checkbox id=\"terms\" />\n",
            "      <label\n",
            "        htmlFor=\"terms\"\n",
            "        className=\"text-sm font-medium leading-none peer-disabled:cursor-not-allowed peer-disabled:opacity-70\"\n",
            "      >\n",
            "        Accept terms and conditions\n",
            "      </label>\n",
            "    </div>\n",
            "  )\n",
            "}```\n",
            "<|EOT|>.\n",
            "Installed CUDA version 12.2 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination\n",
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/cpu_adam...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/cpu_adam/build.ninja...\n",
            "Building extension module cpu_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[2024-07-16 16:38:32,621] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 8359\n",
            "[2024-07-16 16:38:32,622] [ERROR] [launch.py:325:sigkill_handler] ['/usr/bin/python3', '-u', 'finetune_deepseekcoder.py', '--local_rank=0', '--model_name_or_path', 'deepseek-ai/deepseek-coder-1.3b-instruct', '--data_path', '/content/alpaca_instruct.jsonl', '--output_dir', '/content/DeepSeek-Coder/finetune', '--num_train_epochs', '3', '--model_max_length', '1024', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '100', '--save_total_limit', '100', '--learning_rate', '2e-5', '--warmup_steps', '10', '--logging_steps', '1', '--lr_scheduler_type', 'cosine', '--gradient_checkpointing', 'True', '--report_to', 'tensorboard', '--deepspeed', 'configs/ds_config_zero3.json', '--fp16', 'True'] exits with return code = -9\n",
            "[1/3] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/includes -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX512__ -D__ENABLE_CUDA__ -c /usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o \n",
            "[2/3] c++ -MMD -MF cpu_adam_impl.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/includes -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX512__ -D__ENABLE_CUDA__ -c /usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam/cpu_adam_impl.cpp -o cpu_adam_impl.o \n",
            "[3/3] c++ cpu_adam.o cpu_adam_impl.o -shared -lcurand -L/usr/local/lib/python3.10/dist-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o cpu_adam.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JVU_ktSFevO_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}